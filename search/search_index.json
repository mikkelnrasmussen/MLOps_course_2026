{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#documentation","title":"Documentation","text":"<p>Documentation for mlops_course</p>"},{"location":"api/","title":"My API","text":""},{"location":"api/#mlops_course.model.SimpleModel","title":"mlops_course.model.SimpleModel","text":"<p>               Bases: <code>LightningModule</code></p> <p>Simple CNN model.</p> <p>Parameters:</p> Name Type Description Default <code>channels_in</code> <code>int</code> <p>Number of input channels.</p> <code>1</code> <code>hidden_dims</code> <code>list</code> <p>List of hidden dimensions.</p> <code>[32, 64, 128]</code> <code>num_classes</code> <code>int</code> <p>Number of output classes.</p> <code>10</code> <code>kernel_size</code> <code>int</code> <p>Size of convolution kernel.</p> <code>3</code> <code>stride</code> <code>int</code> <p>Stride of convolution.</p> <code>1</code> <code>dropout_rate</code> <code>float</code> <p>Dropout rate.</p> <code>0.5</code> <code>lr</code> <code>float</code> <p>Learning rate.</p> <code>0.001</code> Source code in <code>src/mlops_course/model.py</code> <pre><code>class SimpleModel(LightningModule):\n    \"\"\"Simple CNN model.\n\n    Args:\n        channels_in: Number of input channels.\n        hidden_dims: List of hidden dimensions.\n        num_classes: Number of output classes.\n        kernel_size: Size of convolution kernel.\n        stride: Stride of convolution.\n        dropout_rate: Dropout rate.\n        lr: Learning rate.\n    \"\"\"\n\n    def __init__(\n        self,\n        channels_in: int = 1,\n        hidden_dims: list = [32, 64, 128],\n        num_classes: int = 10,\n        kernel_size: int = 3,\n        stride: int = 1,\n        dropout_rate: float = 0.5,\n        lr: float = 1e-3,\n    ) -&gt; None:\n        super().__init__()\n        self.save_hyperparameters()\n\n        self.conv1 = nn.Conv2d(channels_in, hidden_dims[0], kernel_size, stride)\n        self.conv2 = nn.Conv2d(hidden_dims[0], hidden_dims[1], kernel_size, stride)\n        self.conv3 = nn.Conv2d(hidden_dims[1], hidden_dims[2], kernel_size, stride)\n        self.dropout = nn.Dropout(dropout_rate)\n        self.fc1 = nn.Linear(hidden_dims[2], num_classes)\n\n        self.loss_fn = nn.CrossEntropyLoss()\n\n        self.accuracy = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=num_classes)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"Forward pass.\n\n        Args:\n            x: Input tensor expected to be of shape [B, C, H, W].\n\n        Returns:\n            Output tensor of shape [B, num_classes].\n        \"\"\"\n        x = torch.relu(self.conv1(x))\n        x = torch.max_pool2d(x, 2, 2)\n        x = torch.relu(self.conv2(x))\n        x = torch.max_pool2d(x, 2, 2)\n        x = torch.relu(self.conv3(x))\n        x = torch.max_pool2d(x, 2, 2)\n        x = torch.flatten(x, 1)\n        x = self.dropout(x)\n        return self.fc1(x)\n\n    def evaluate(self, batch, stage=None):\n        img, target = batch\n        logits = self(img)\n        loss = self.loss_fn(logits, target)\n        preds = torch.argmax(logits, dim=1)\n        acc = self.accuracy(preds, target)\n\n        if stage:\n            self.log(f\"{stage}_loss\", loss, prog_bar=True)\n            self.log(f\"{stage}_acc\", acc, prog_bar=True)\n\n        return loss\n\n    def training_step(self, batch, batch_idx):\n        \"\"\"Training step.\"\"\"\n        if batch_idx % 200 == 0 and self.logger is not None and hasattr(self.logger, \"experiment\"):\n            x, _ = batch\n            grid = torchvision.utils.make_grid(x[:16].detach().cpu(), nrow=4, normalize=True)\n            self.logger.experiment.log(\n                {\"train/samples\": wandb.Image(grid, caption=\"Train batch samples\")},\n                step=int(self.global_step),\n            )\n        return self.evaluate(batch, \"train\")\n\n    def validation_step(self, batch, batch_idx):\n        return self.evaluate(batch, \"val\")\n\n    def test_step(self, batch, batch_idx):\n        return self.evaluate(batch, \"test\")\n\n    def configure_optimizers(self):\n        \"\"\"Configure optimizer.\"\"\"\n        return optim.Adam(self.parameters(), lr=self.hparams.lr)\n</code></pre>"},{"location":"api/#mlops_course.model.SimpleModel.configure_optimizers","title":"configure_optimizers","text":"<pre><code>configure_optimizers()\n</code></pre> <p>Configure optimizer.</p> Source code in <code>src/mlops_course/model.py</code> <pre><code>def configure_optimizers(self):\n    \"\"\"Configure optimizer.\"\"\"\n    return optim.Adam(self.parameters(), lr=self.hparams.lr)\n</code></pre>"},{"location":"api/#mlops_course.model.SimpleModel.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Forward pass.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor expected to be of shape [B, C, H, W].</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Output tensor of shape [B, num_classes].</p> Source code in <code>src/mlops_course/model.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Forward pass.\n\n    Args:\n        x: Input tensor expected to be of shape [B, C, H, W].\n\n    Returns:\n        Output tensor of shape [B, num_classes].\n    \"\"\"\n    x = torch.relu(self.conv1(x))\n    x = torch.max_pool2d(x, 2, 2)\n    x = torch.relu(self.conv2(x))\n    x = torch.max_pool2d(x, 2, 2)\n    x = torch.relu(self.conv3(x))\n    x = torch.max_pool2d(x, 2, 2)\n    x = torch.flatten(x, 1)\n    x = self.dropout(x)\n    return self.fc1(x)\n</code></pre>"},{"location":"api/#mlops_course.model.SimpleModel.training_step","title":"training_step","text":"<pre><code>training_step(batch, batch_idx)\n</code></pre> <p>Training step.</p> Source code in <code>src/mlops_course/model.py</code> <pre><code>def training_step(self, batch, batch_idx):\n    \"\"\"Training step.\"\"\"\n    if batch_idx % 200 == 0 and self.logger is not None and hasattr(self.logger, \"experiment\"):\n        x, _ = batch\n        grid = torchvision.utils.make_grid(x[:16].detach().cpu(), nrow=4, normalize=True)\n        self.logger.experiment.log(\n            {\"train/samples\": wandb.Image(grid, caption=\"Train batch samples\")},\n            step=int(self.global_step),\n        )\n    return self.evaluate(batch, \"train\")\n</code></pre>"}]}